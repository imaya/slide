<!--
Google IO 2012/2013 HTML5 Slide Template

Authors: Eric Bidelman <ebidel@gmail.com>
         Luke Mahé <lukem@google.com>

URL: https://code.google.com/p/io-2012-slides
-->
<!DOCTYPE html>
<html>
<head>
  <title></title>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <!--<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">-->
  <!--<meta name="viewport" content="width=device-width, initial-scale=1.0">-->
  <!--This one seems to work all the time, but really small on ipad-->
  <!--<meta name="viewport" content="initial-scale=0.4">-->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="google" value="notranslate">
  <link rel="stylesheet" media="all" href="theme/css/default.css">
  <link rel="stylesheet" media="only screen and (max-device-width: 480px)" href="theme/css/phone.css">
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
  <script data-main="js/slides" src="js/require-1.0.8.min.js"></script>
</head>
<body style="opacity: 0">

<slides class="layout-widescreen">

  <slide class="title-slide segue nobackground">
    <!--
    <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
    -->
    <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
      <p data-config-presenter><!-- populated from slide_config.json --></p>
      <p data-config-contact><!-- populated from slide_config.json --></p>
    </hgroup>
  </slide>

  <slide>
    <hgroup>
      <h2>Web Audio API とは</h2>
    </hgroup>
    <article>
      <ul>
        <li>雑な説明: JavaScript で音関係ほとんどなんでもできるようにする API</li>
        <li>音データの読み込み<br/>ブラウザで対応している場合 *.wav, *.mp3 や *.ogg などもデコードして使える</li>
        <li>オシレータによる波形から音の生成</li>
        <li>JavaScript による波形の操作</li>
        <li>最近の API なので各環境でメソッド名が違ったり細かいところに違いがある</li>
        <li>Mozilla Firefox では Audio Data API という似たような機能のものがあったが Web Audio API に合流するため気にしないで良い</li>
        <li>iOS Safari ではユーザのアクションから発火されたイベントじゃないと音がならなかったり罠もたくさんある</li>
        <li><a href="http://www.w3.org/TR/webaudio/">仕様</a>は<a href="https://sites.google.com/site/miuraoff/web-audio-apinosupekku">和訳もあります</a>がかなり古いので読むときは最新版と合わせて読む</li>
      </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Web Audio API の簡単な使い方(概要)</h2>
    </hgroup>
    <article>
      <p>パイプをゴールまで繋げて水を流す感じ</p>

      <h3>AudioNode をつなげていく</h3>
      <ul>
        <li>AudioNode 同士をつなげていって、最終的に AudioContext の destination につなげて音を出す</li>
        <li>AudioNode には波形データから音を鳴らしたりオシレータから鳴らしたりするものや、音量調節やローパスフィルタやパニング、JavaScript で波形の操作をするものなどいろいろあります</li>
        <li>音量などの値はスケジュールを組んで変化させることができる</li>
      </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Web Audio API の簡単な使い方</h2>
    </hgroup>
    <article>
      <ul>
        <li>AudioContext オブジェクトを作る (webkit とかの prefix がついたりする)</li>
        <li>AudioContext から用途に応じて好きな AudioNode を作る（たとえば createGain など）</li>
        <li>AudioNode 同士を connect メソッドでつなげる(最終的には AudioContext#destination に connect する)</li>
        <li>音量などのパラメータをスケジュールするのは <a href="http://www.w3.org/TR/webaudio/#example1-AudioParam-section">AudioParam の setValueAtTime や linearRampToValueAtTime などのメソッド</a>を使う</li>
      </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Web Audio API の簡単な使い方</h2>
      <h3>実際のコード例</h3>
    </hgroup>
    <article class="smaller_">
      <pre class="prettyprint" data-lang="javascript">
// audioData は ArrayBuffer
function sound(audioData) {
  var ctx = new webkitAudioContext();
  var bufferSource = ctx.createBufferSource();

  // AudioBufferSourceNode を AudioContext#destnation につなぐ
  bufferSource.connect(ctx.destination);

  // AudioData をデコードして AudioBuffer にする
  ctx.decodeAudioData(audioData, function(buffer) {
    // AudioBufferSourceNode にデコードしたデータをセットする
    bufferSource.buffer = buffer;

    // 音を鳴らす
    bufferSource.start(0);
  });
}
</pre>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>smfplayer.js, sf2synth.js とは</h2>
    </hgroup>
    <article>
      <h3>smfplayer.js: 標準 MIDI ファイルプレイヤー</h3>
        <ul>
          <li>標準 MIDI ファイル(以下 SMF )を読み込んで WebMidiLink 対応のシンセサイザを鳴らす</li>
          <li>MFi(着メロ) にもこっそり対応してる
            <ul>
              <li>MFi の場合は SMF に変換する処理が入る</li>
            </ul>
          </li>
        </ul>
      <h3>sf2synth.js: SoundFont シンセサイザ</h3>
        <ul>
          <li>SoundFont を WebMidiLink の音源として使えるようにする</li>
          <li>Windows などは標準のMIDI音源があるが、ブラウザでは利用できないので必要</li>
        </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>WebMidiLink</h2>
    </hgroup>
    <article>
      <ul>
        <li>ブラウザで動作するシンセサイザを鳴らすための仕様</li>
        <li>ざっくり言うと MIDI メッセージやシンセサイザ情報のやり取りを window.postMessage で行うときのルール</li>
      </ul>

      <figure>
        <img src="images/web-midi-link.svg">
        <figcaption>Host App は WebMidiLink 対応のシンセサイザを自由に付け替えて鳴らすことができる</figcaption>
      </figure>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>SoundFont とは</h2>
    </hgroup>
    <article>
      <ul>
        <li>サンプラーのデータフォーマット</li>
        <li>今の主流は SoundFont2 (*.sf2)</li>
        <li>GM (General MIDI: 一般的なMIDI) の音色マップに対応した形のデータもある</li>
        <li>音色の音域毎に、サンプリングされた音とその音の音程やループポイントなどが指定されている</li>
        <li>Windows では標準のMIDI音源 (MSGS: Microsoft GS Wavetable SW Synth) を嫌がって Timidity++ というソフトウェアで SoundFont を使う人も多い</li>
        <li>結構サイズは大きい(数MB-1GBクラスのものもある)</li>
      </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>sf2synth.js における SoundFont の扱い(概要)</h2>
    </hgroup>
    <article>
      <h3>対応機能</h3>
      <ul>
        <li>音程の変化は平均律を再生速度の変更で行うことで実装</li>
        <li>Volume/Modulation Envelope 対応</li>
        <li>再生中の pitch bend (音程変更パラメータ)の変更に対応</li>
      </ul>
      <h3>Envelope</h3>
      <ul>
        <li>いわゆる ADSR というパラメータ。 以下は Volume Envelope の時の例(Modulation Envelope の場合は音量ではなく変化させる度合いとなる)</li>
        <li>Attack: 鳴らし始めて最大音量になるまでの時間</li>
        <li>Decay: Sustain レベルになるまでの時間</li>
        <li>Sustain: 鳴らし続けているときの音量</li>
        <li>Release: 鳴らし終わった時、完全に消えるまでの時間</li>
        <li>SoundFont では Delay(立ち上がりまでの遅延時間), Hold(最大音量を維持する時間) というパラメータもある</li>
      </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>ADSR Envelope</h2>
    </hgroup>
    <article>
      <figure>
        <img src="images/ADSR_parameter.svg" width="80%">
        <figcaption>出典: Wikipedia (http://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope)</figcaption>
      </figure>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>sf2synth.js における SoundFont の扱い</h2>
      <h3>ノードの作成とスケジュール</h3>
    </hgroup>
    <article>
      <h3>NoteOn ごとに BufferSource をつくって使い捨てる</h3>
      <ul>
        <li>作った BufferSource に Panner(左右の音量バランスの調整), GainNode(チャンネル単位の音量変更), BiquadFilter(ローパスフィルタ) をつなげる</li>
        <li>ADSR は AudioParam のスケジュール機能を利用 (setValueAtTime, linearRampToValueAtTime)</li>
        <li><a href="http://www.w3.org/TR/2013/WD-webaudio-20131010/#DynamicLifetime">使いすてるのも想定されている用途</a>なのでガンガン使っても割りといける</li>
        <li>というか BufferSource は止めたら再生できなくなるので使い捨てるしかない</li>
      </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>sf2synth.js における SoundFont の扱い</h2>
      <h3>ノードの作成とスケジュール</h3>
    </hgroup>
    <article>
      <p>NoteOn ごとに点線内のノードがつくられる</p>
      <img src="images/sf2synth-note.svg" width="80%">
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>sf2synth.js における SoundFont の扱い</h2>
      <h3>キーを押しっぱなしにしている場合</h3>
    </hgroup>
    <article>
      <ul>
        <li>SoundFont には各サンプルにループの開始と終わりが指定されている</li>
        <li>AudioBufferSourceNode の loopStart, loopEnd に指定して再生する</li>
      </ul>

      <figure>
        <img src="images/wave.png" height="150">
        <figcaption class="smaller">SoundFont に含まれる波形データとループポイント(赤くなっている区間がループ)</figcaption>
      </figure>

      <figure>
        <img src="images/waveloop.png" height="150">
        <figcaption>上記のループポイントを拡大</figcaption>
      </figure>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>デモ</h2>
    </hgroup>
    <article>
      <h3>時間があったらやるけど多分ない</h3>

      <p><a href="http://imaya.github.io/demo/sf2.js/">http://imaya.github.io/demo/sf2.js/</a></p>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Web Audio API の感想など</h2>
    </hgroup>
    <article>
      <h3>良かった点</h3>
      <ul>
        <li>パフォーマンス的にきつそうかな、と思っていた使い捨て方式は意外といけた</li>
        <li>日本で活発に活動してる人がいるので日本語で参考になる資料や事例が多い</li>
      </ul>

      <h3>今後に期待</h3>
      <ul>
        <li>Pitch Bend の変更で行われる頻繁に再生速度を変更する処理は重いので、特にモバイルではきつい</li>
        <li>ビブラートの実装が現状では ScriptProcessorNode 使うしかなさそうなので(設計的にもパフォーマンス的にも)無理<br/>仕様上はできるはずなのでそのうちできるようになったら実装する</li>
      </ul>
    </article>
  </slide>

  <slide class="thank-you-slide segue nobackground">
    <!--aside class="gdbar right"><img src="images/google_developers_icon_128.png"></aside-->
    <article class="flexbox vleft auto-fadein">
      <h2>おわり</h2>
    </article>
    <p class="auto-fadein" data-config-contact>
      <!-- populated from slide_config.json -->
    </p>
  </slide>

  <slide class="backdrop"></slide>

</slides>

</body>
</html>
